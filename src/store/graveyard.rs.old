use std::{
    io::{Cursor, Read, Write},
    mem::size_of,
    path::PathBuf,
    time::Duration,
};

use log::{debug, trace};
use necronomicon::{Decode, Encode, Pool, PoolImpl, Shared};

use crate::{
    buffer::InMemBuffer,
    dequeue::{self, Popper},
    entry::Metadata,
};

use super::BufferOwner;

// Only compacts the data files, we just write over the meta file.
// Several things to look out for:
// - crash during compaction of files and moving into new file(s)
// - crash during deletion of old file(s)
// - crash during update of meta file
//
// We will do the following:
// 0. write all tombstones to compact meta file
// 1. copy live data from nodes into new file(s) but not part of dequeue yet! (don't intersperse with incoming data)
// 2. swap the new file(s) into the dequeue (these should be less than the node size)
// 3. delete old file(s) (may not be there if read out before compaction completes)
// 4. update meta file to say old slots are available for new data
// 5. update compact meta file to remove tombstones
//
pub struct Graveyard {
    dir: PathBuf,
    popper: Popper,
    pool: PoolImpl,
}

impl Graveyard {
    pub(crate) fn new(mut dir: PathBuf, popper: Popper) -> Self {
        let block_size = usize::try_from(Metadata::struct_size(crate::entry::Version::V1))
            .expect("u32 -> usize")
            + TOMBSTONE_LEN;

        trace!("block_size: {}", block_size);
        dir.push("data");
        trace!("creating graveyard at {dir:?}");
        Self {
            dir,
            popper,
            pool: PoolImpl::new(block_size, 1),
        }
    }

    // The problem is we also need to update the metadata for the dequeue.
    // We can't just delete the data, we need to update the metadata to say
    // that the data is no longer there and somewhere else (if just moved).;p[''']
    pub fn bury(self, interval: u64) -> ! {
        let interval = Duration::from_secs(interval);
        loop {
            // Collect all the files to compact.
            let tombs = self.collect();
            println!(
                "compacting {} tomb(s)",
                tombs.iter().map(|x| x.len()).sum::<usize>()
            );

            for tomb in tombs {
                let file = tomb[0].file;
                let path = format!("{}.bin", file);
                let out = self.dir.join(format!("{}.new", path));
                let path = self.dir.join(path);

                // If file doesn't exist, then we have already compacted it, or removed it.
                if let Ok(mut file) = std::fs::File::open(path.clone()) {
                    let len = file.metadata().expect("no file metadata").len();
                    trace!("compacting file: {} len: {}", path.display(), len);
                    let mut in_buf = InMemBuffer::new(len);

                    file.read_exact(in_buf.as_mut())
                        .expect("failed to read file");

                    println!("in_buf: {:?}", in_buf.as_ref().bytes());
                    let out_buf = Self::compact_buf(tomb, in_buf);
                    println!("out_buf: {:?}", out_buf);

                    let mut has_data = !out_buf.is_empty();
                    has_data &= out_buf.iter().copied().map(u64::from).sum::<u64>() != 0;

                    if has_data {
                        let mut out =
                            std::fs::File::create(out.clone()).expect("failed to create file");

                        out.write_all(&out_buf).expect("failed to write file");
                    }

                    std::fs::remove_file(path.clone()).expect("failed to remove file");
                    if has_data {
                        std::fs::rename(out, path.clone()).expect("failed to rename file");
                    }
                }
            }

            std::thread::sleep(interval);
        }
    }

    fn collect(&self) -> Vec<Vec<Tombstone>> {
        let mut nodes = vec![];
        let mut node = 0;

        loop {
            let mut buf = self.pool.acquire(BufferOwner::Graveyard);

            // If we crash and it happens to be that tombstones map to same spot as different data,
            // then we will delete data we should keep. Is this true still?
            if let Ok(data) = self.popper.pop(&mut buf) {
                match data {
                    dequeue::Pop::Popped(data) => {
                        data.verify().expect("failed to verify data");
                        let data = data.into_inner();
                        let tomb = Tombstone::decode(&mut Cursor::new(data.data().as_slice()))
                            .expect("failed to decode tombstone");

                        if nodes.is_empty() {
                            nodes.push(vec![]);
                        }

                        if nodes[node].is_empty() {
                            nodes[node].push(tomb);
                        } else {
                            let last = nodes[node].last().expect("no tombstones in node");
                            if tomb.file == last.file {
                                nodes[node].push(tomb);
                            } else {
                                node += 1;
                                nodes.push(vec![]);
                                nodes[node].push(tomb);
                            }
                        }
                    }
                    dequeue::Pop::WaitForFlush => {
                        break;
                    }
                }
            } else {
                break;
            }
        }

        nodes
    }

    // We can maybe fix the problem of accidentally deleting data we don't want by
    // comparing crcs of the data and tombstones.
    fn compact_buf(mut tombs: Vec<Tombstone>, in_buf: InMemBuffer) -> Vec<u8> {
        if tombs.is_empty() {
            return in_buf.as_ref().to_vec();
        }

        println!("tombs: {:?}", tombs);
        let first = tombs.first().expect("no tombstones");

        assert!(tombs.iter().all(|x| x.file == first.file));

        let mut out_buf = vec![];

        // compact the tombstones first
        tombs.sort_by(|a, b| a.offset.cmp(&b.offset));

        let mut reduced_tombs = vec![];
        for tomb in tombs {
            if reduced_tombs.is_empty() {
                reduced_tombs.push(tomb);
            } else {
                let last = reduced_tombs.last().expect("no tombstones");
                if last.offset + last.len == tomb.offset {
                    reduced_tombs.last_mut().expect("no tombstones").len += tomb.len;
                } else if last.offset == tomb.offset {
                    // skip
                } else {
                    reduced_tombs.push(tomb);
                }
            }
        }

        let first = reduced_tombs.first().expect("no tombstones");

        // copy the data from beginning to first tombstone
        out_buf.extend_from_slice(&in_buf.as_ref()[0..first.offset as usize]);
        println!("reduced tombs: {:?}", reduced_tombs);

        let mut begin = first.offset + first.len;
        for tomb in reduced_tombs.iter().skip(1) {
            out_buf.extend_from_slice(&in_buf.as_ref()[begin as usize..tomb.offset as usize]);
            begin = tomb.offset + tomb.len;
        }

        out_buf.extend_from_slice(&in_buf.as_ref()[begin as usize..]);

        out_buf
    }
}
